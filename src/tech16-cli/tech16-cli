#!/usr/bin/env python3
"""tech16-cli - Command line tool for querying LLMs with custom prompts and context."""

import argparse
import sys
import os
from typing import List, Optional

# Add the lib directory to the Python path to import our client library
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "lib"))

from client.client import create_client
from client.config import SUPPORTED_MODELS
from client.exceptions import error_exit
from client.file_handler import read_file_content, validate_file_paths
from client.url_handler import scrape_url_content, validate_urls, is_valid_url


def print_usage_and_exit() -> None:
    """Print comprehensive usage message with providers/models and exit."""
    print(
        """tech16-cli - Query LLMs with custom prompts and context

USAGE:
  tech16-cli [OPTIONS] [FILES_AND_URLS...]

OPTIONS:
  --prompt FILENAME    File containing the system prompt to use (optional)
  --model MODEL_NAME   Model to use (default: o4-mini)
  --help               Show this help message

EXAMPLES:
  tech16-cli file.txt
  tech16-cli --model claude-sonnet-4 file.txt
  tech16-cli --prompt system.txt --model o4-mini https://example.com/docs
  echo "analyze this" | tech16-cli --prompt review.txt hello.py
  tech16-cli --prompt plan.txt file1.py file2.py https://docs.example.com

SUPPORTED PROVIDERS AND MODELS:"""
    )

    for provider, models in sorted(SUPPORTED_MODELS.items()):
        print(f"\n  {provider.upper()}:")
        for model in sorted(models):
            default_marker = " (default)" if model == "o4-mini" else ""
            print(f"    - {model}{default_marker}")

    print(
        f"\nTotal models available: {sum(len(models) for models in SUPPORTED_MODELS.values())}"
    )
    print("\nNOTE: Requires appropriate API keys set as environment variables:")
    print("  - ANTHROPIC_API_KEY for Anthropic models")
    print("  - OPENAI_API_KEY for OpenAI models")
    print("  - GOOGLE_API_KEY for Gemini models")

    sys.exit(0)


def read_stdin() -> Optional[str]:
    """Read input from stdin if available."""
    if not sys.stdin.isatty():
        try:
            content = sys.stdin.read().strip()
            return content if content else None
        except Exception as e:
            error_exit(f"Failed to read from stdin: {e}")
    return None


def build_context(
    stdin_content: Optional[str], files_and_urls: List[str], prompt: str = ""
) -> List[str]:
    """Build the context array from stdin, files, URLs, and prompt."""
    context = []

    # Add stdin content first if available
    if stdin_content:
        context.append(f"Input from stdin:\n{stdin_content}")

    # Process files and URLs with improved error handling
    for item in files_and_urls:
        if is_valid_url(item):
            print(f"Scraping URL: {item}", file=sys.stderr)
            url_content = scrape_url_content(item)
            context.append(url_content)
        else:
            # Handle as file
            file_content = read_file_content(item)
            context.append(file_content)

    # Add prompt as the last entry if provided
    if prompt:
        context.append(prompt)

    return context


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="tech16-cli - Query LLMs with custom prompts and context",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  tech16-cli --model claude-sonnet-4 file.txt
  tech16-cli --prompt system.txt --model o4-mini https://example.com/docs
  echo "analyze this" | tech16-cli --prompt review.txt
  tech16-cli --prompt plan.txt file1.py file2.py https://docs.example.com
        """,
    )

    # Prompt file specification
    parser.add_argument("--prompt", help="File containing the prompt to use")

    # Model specification
    parser.add_argument(
        "--model", default="o4-mini", help="Model to use (default: o4-mini)"
    )

    # Files and URLs
    parser.add_argument(
        "files_and_urls", nargs="*", help="Files and URLs to include as context"
    )

    return parser.parse_args()


def main():
    """Main entry point for the CLI tool."""
    try:
        # Parse command line arguments
        args = parse_arguments()

        # Validate file and URL inputs early
        if args.files_and_urls:
            files = [item for item in args.files_and_urls if not is_valid_url(item)]
            urls = [item for item in args.files_and_urls if is_valid_url(item)]

            # Validate files
            file_errors = validate_file_paths(files)
            if file_errors:
                for error in file_errors:
                    print(f"Error: {error}", file=sys.stderr)
                error_exit("File validation failed")

            # Validate URLs
            url_errors = validate_urls(urls)
            if url_errors:
                for error in url_errors:
                    print(f"Error: {error}", file=sys.stderr)
                error_exit("URL validation failed")

        # Read stdin if available
        stdin_content = read_stdin()

        # Read prompt file if specified
        prompt = ""
        if args.prompt:
            prompt_content = read_file_content(args.prompt)
            # Check if it's an error message
            if prompt_content.startswith("Error:"):
                error_exit(prompt_content[7:])  # Remove "Error: " prefix
            prompt = prompt_content

        # Check if we have no input at all - show help if so
        has_stdin = stdin_content is not None and stdin_content.strip()
        has_prompt = args.prompt is not None
        has_files_urls = len(args.files_and_urls) > 0

        if not has_stdin and not has_prompt and not has_files_urls:
            print_usage_and_exit()

        # Build context array
        context = build_context(stdin_content, args.files_and_urls, prompt)

        # Create appropriate client
        client = create_client(args.model)

        # Execute query
        print(f"Querying {args.model}...", file=sys.stderr)
        try:
            response = client.query(args.model, context)
            print(response)
        except Exception as e:
            error_exit(f"Query failed: {e}")

    except KeyboardInterrupt:
        error_exit("Operation cancelled by user", 130)
    except Exception as e:
        error_exit(f"Unexpected error: {e}")


if __name__ == "__main__":
    main()
